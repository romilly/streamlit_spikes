# Generated by ChatGPT, heavily modified by me

from dotenv import load_dotenv
import streamlit as st
from mistralai.client import MistralClient
from mistralai.models.chat_completion import ChatMessage
import os
from pew.chat.sqlite_recorder import SQLiteChatRecorder
import socket

hostname = socket.gethostname()

# Function to send requests to Mistralx API

# Streamlit app

load_dotenv()
api_key = os.environ["MISTRAL_API_KEY"]
models = ["mistral-tiny", "mistral-small", "mistral-medium"]
client = MistralClient(api_key=api_key)
recorder = SQLiteChatRecorder('/home/romilly/git/active/streamlit_spikes/data/chats.db')
st.title("Conversation with Mistral Models")
if prompt := st.chat_input():
    st.chat_message("user").write(prompt)
    messages = [ChatMessage(role="user", content=prompt)]
    responses = list(client.chat(
        model=model,
        messages=messages,
        ).choices[0].message.content for model in models)
    for response, model in zip(responses, models):
        st.chat_message("assistant").write(f"{model}: {response}")
        recorder.add_record(hostname, {'model': model, 'user_input': prompt, 'response': response})
